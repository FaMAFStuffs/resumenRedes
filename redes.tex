\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{lmodern}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{graphicx}
\author{Agustin Curto, agucurto95@gmail.com}
\title{Resumen Redes y Sistemas Distribuidos}
\date{2016}

\begin{document}
\maketitle
\tableofcontents

\chapter{INTRODUCCIÓN}
\par Una red de computadoras es un conjunto de computadoras autónomas 
interconectadas. Dos computadoras están interconectadas si pueden intercambiar 
información. La conexión puede hacerse por medio de: cable de cobre, fibra óptica, 
microondas, rayos infrarrojos, satélites de comunicaciones, etc.
\par Si bien los tipos de redes no cambian, si evoluciona la tecnología de hardware en 
la que se basa, y como consecuencia el funcionamiento o desempeño de las redes de 
cada tipo van mejorando más y más.

\section{Uso de las redes de las computadoras}
\par Aplicaciones de negocios
\par Aplicaciones domésticas
\par Usuarios móviles
\par Cuestiones sociales

\section{Hardware de red}
\par Dos tipos de tecnología de transmisión:
	\begin{itemize}
		\item Las redes de difusión tienen un solo canal de comunicación, por lo que 
		todas las máquinas de la red lo comparten.
		\item En las redes punto a punto un paquete podría tener que visitar una o más 
		máquinas intermedias. Puede haber varias rutas diferentes y hay que encontrar la 
		correcta.
	\end{itemize}
\par Las redes más pequeñas suelen usar difusión, mientras que las más grandes 
conectan redes pequeñas punto a punto.

\subsection{Redes de área local}
\par Las redes de área local, generalmente llamadas LAN (Local Area Networks), son 
redes de propiedad privada que operan dentro de un solo edificio, como una casa, 
oficina o fábrica.

\subsubsection{Difusión}
\par Si una máquina envía un mensaje todas las demás lo reciben, dentro del mensaje 
se indica el destinatario. Una máquina al recibir un paquete analiza si va destinado a 
ella y en ese caso lo procesa, sino lo ignora. Otras variantes son: \textit{broadcasting}, 
consiste en enviar un paquete a todos y \textit{multicasting} envia a un grupo 
particular.
\par Ejemplos de redes de área local son WIFI y Ethernet.

\textbf{WiFi:} son redes inalámbricas, operan a velocidades desde 11 hasta cientos de 
Mbps.

\textbf{Ethernet:} Son redes de difusión basada en bus con control descentralizado 
que funcionan de 10 Mbps a 10 Gbps. Se puede transmitir siempre que se desee; si 
dos paquetes colisionan, es decir mas de una máquina escribiendo simultáneamente en 
el cable, se espera un tiempo aleatorio e intenta más tarde.

\begin{center} 
	\includegraphics[width=8cm, height=6cm]{./imagenes/arealocal.png} 
\end{center}

\subsection{Redes de área metropolitana}
\par Una Red de área Metropolitana, o MAN (Metropolitan Area Network), cubre toda 
una ciudad. \\

\textbf{Ejemplo 1:} MAN basada en TV por cable
	\begin{itemize}
		\item Cable coaxil para unir varias casas.
		\item Elementos de conmutación.
		\item Elementos de conmuntación se unen por cables de fibra óptica.
	\end{itemize}
	
	\begin{center}
		\includegraphics[width=10cm, height=6cm]{./imagenes/metropolitana1.png} 
	\end{center}

\textbf{Ejemplo 2:} Wimax (estándar 802.16).
	\begin{itemize}
		\item Se envían paquetes por el aire en lugar de usar cable o redes telefónicas.
		\item Se conecta a internet (a una red dorsal).
		\item Se puede acceder a la red desde computadoras en casas o edificios, o 
		desde vehículos en movimiento.
	\end{itemize}	 
	
	\begin{center}
		\includegraphics[width=10cm, height=6cm]{./imagenes/metropolitana2.png} 
	\end{center}

\subsection{Redes de área amplia}
\par Una Red de área Amplia, o WAN (Wide Area Network), abarca una extensa área 
geográfica, por lo general un país o continente. Son redes punto a punto: dos 
dispositivos están conectados entre sí por medio de un cable, esta regla da lugar a lo 
que se llama subred.
\par Una \textbf{subred} posee varios enrutadores conectados entre sí formando un 
grafo. A una subred pueden estar conectadas computadoras o redes de área local 
enteras, para ir de una máquina a otra hay distintas rutas alternativas.
\par Los elementos de conmutación, tambien llamados enrutadores dependiendo de la capa de red en la actúan, conectan tres o más líneas de transmisión. Los datos por línea de entrada se envían por alguna línea de salida elegida especialmente.
Dos enrutadores que no comparten una línea de transmisión se conectan indirectamente a través de otros enrutadores.

Un paquete se envía de un enrutador a otro a través de enrutadores intermedios, almacenándose enteramente en cada enrutador intermedio hasta que la línea requerida de salida esté libre y luego se reenvía (store-and-forward). Otra forma sería no guardar el mensaje, no esperar a que llegue entero antes de reenviarlo (cut-through).

Los mensajes se dividen en paquetes, los cuales tienen un número de secuencia. Estos paquetes se mandan en la red de uno en uno. Los paquetes se van depositando en el host receptor que reensambla el mensaje original. En algunas redes todos los paquetes del mensaje deben seguir la misma ruta, en otras cada paquete se enruta por separado. Las decisiones de enrutamiento se hacen de manera local, un algoritmo de enrutamiento describe la manera en que un enrutador toma esa decisión.

\subsubsection{Ejemplos de WAN:}
\begin{itemize}
\item Sistema telefónico fijo (Ej:. ADSL):
\begin{itemize}
	\item Cada domicilio conectado por un cable de cobre a una End office
 	\item Toll offices usadas para reenvío de mensajes.
 	\item Toll offices unidas por cables de fibra óptica llamados troncales.
\end{itemize}	

\begin{center} 
	\includegraphics[width=8cm, height=6cm]{./imagenes/telefonico.png} 
\end{center}

\item Una red de teléfonos celulares (Ej: 3G o 4G).
\begin{itemize}
	\item Celdas con estaciones base: cada smartphone opera en una celda.
	\item Celdas conectados a centros de conmutación: para conectar distintas celdas
 	\item Centros de conmutación conectados a la red telefónica pública.
\end{itemize}

\end{itemize}

\par Un proveedor de servicios de internet (PSI) es también una WAN. Los clientes compran conectividad a un PSI y para usar su red.

\subsection{Interredes}
\par Existen mucha redes en el mundo, a veces con hardware y software diferente. 
Con frecuencia las personas conectadas a una red desean comunicarse con las 
personas conectadas a otra red diferente. Las puertas de enlace proveen la conexión y 
la traducción necesaria. Un conjunto de redes interconectadas se llama interred 
(internet), Internet es una inter red.

\begin{center} 
	\includegraphics[width=8cm, height=6cm]{./imagenes/interred.png} 
\end{center}

\section{Software de red}
\par Las primeras redes de computadoras se diseñaron teniendo en cuenta al hardware 
como punto principal y al software como secundario. Pero esta estrategia ya no 
funciona. Ahora el software de red está muy estructurado.

\subsection{Jerarquías de protocolos}
\par Para reducir la complejidad de su diseño, la mayoría de las redes esta organizada 
como una pila de capas o niveles, cada una construida a partir de la que esta debajo de 
ella. El propósito de cada capa es ofrecer ciertos servicios, a las capas superiores, a las 
cuales no se les muestran los detalles de implementación de los servicios ofrecidos. La 
capa \textit{N} de una maquina mantiene una conversación con la capa \textit{N} de 
otra máquina. Las reglas y convenciones utilizadas en esta conversación se conocen 
como \textbf{protocolo de capa N}.
\par Cada capa pasa los datos y la información de control a la capa inmediatamente 
inferior, hasta que se alcanza la capa más baja. Debajo de la capa 1 se encuentra el 
medio físico, a través del cual ocurre la comunicación real. Entre cada par de capas 
adyacentes esta una \textbf{interfaz} que define que operaciones y servicios 
primitivos pone la capa mas baja a disposición de la capa superior inmediata.
\par El conjunto de capas y protocolos se conoce como \textbf{arquitectura de red} o 
\textbf{nomenclatura de pila de protocolos}.

\par Un proceso de aplicación se ejecuta en la \textit{capa 5}, la cual produce un 
mensaje y lo pasa a la \textit{capa 4} para su transmisión. La \textit{capa 4} pone un 
encabezado en el mensaje para identificarlo y pasa el resultado a la \textit{capa 3}. El 
encabezado contiene información de control como números de secuencia para que la 
\textit{capa 4} de la máquina de destino entregue los mensajes en el orden correcto, 
si las capas inferiores no mantienen la secuencia.

\par En muchas redes no hay limitaciones en el tamaño de los mensajes de la 
\textit{capa 4}, pero casi siempre hay un límite impuesto por el protocolo de la 
\textit{capa 3}, la cual debe dividir  los mensajes que llegan en unidades mas 
pequeñas llamadas \textbf{paquetes} y a cada paquete colocarle un encabezado.
\par La \textit{capa 3} decide cuál de las líneas que salen utilizar y pasa los paquetes 
a la \textit{capa 2} que no solo agrega un encabezado a cada pieza sino tambien un 
terminador, y pasa la unidad resultante a la \textit{capa 1} para su transmisión.
\par En la máquina receptora el mensaje pasa hacia arriba de capa en capa, perdiendo 
los encabezados conforme avanza.

\subsection{Aspectos de diseño para las capas}

Algunos de los aspectos claves de diseño que ocurren en la redes están presentes en 
las diversas capas, cada capa necesita de un mecanismo para identificar a los emisores 
y a los receptores. Es necesario un método para que un proceso en una máquina 
especifique con cual otra máquina quiere hablar, además de una forma de 
\textbf{direccionamiento} a fin de precisar un destino específico.

\par Otras decisiones de diseño conciernen a las reglas de transferencia de datos, en 
algunos sistemas los datos viajan solo en una dirección, en otros pueden viajar en 
ambas direcciones.

El control de errores es un aspecto importante porque los circuitos de comunicación 
física no son perfectos. Muchos códigos de corrección y detección de errores son 
conocidos, pero los dos extremos de la conexión deben estar de acuerdo en cual es el 
que se va a utilizar. Además, el receptor debe tener algun medio de decirle al emisor 
que mensajes se han recibido correctamente y cuáles no.

\par No todos los canales de comunicación conservan el orden en que se envían los 
mensajes. Para tratar con una posible perdida de secuencia, el protocolo debe incluir 
un mecanismo que permita al receptor volver a unir los pedazos en forma adecuada. 
Una solución obvia es numerar las piezas, pero hay que tratar con las piezas que no 
llegan en orden.

\par Hay que evitar que un emisor rápido sature de datos a un receptor lento. Hay 
soluciones a este problema donde el receptor proporciona algún tipo de 
retroalimentación al emisor, directa o indirectamente, dependiendo de la situación real 
del receptor. A este tema se lo denomina c\textbf{control de flujo}. A veces en la red 
demasiadas máquinas quieren enviar demasiados mensajes y la red no puede 
mandarlos a todos, esta sobrecarga se llama \textbf{congestión}. Una solución es que 
cada máquina emisora reduzca el tráfico de salida.

\par En algunos niveles los procesos son incapaces de aceptar mensajes de longitud 
arbitraria. Esta propiedad conduce a mecanismos para desensamblar, transmitir y 
reensamblar mensajes. A este tema en general se lo conoce como 
\textbf{interconexión de redes}.

\par Cuando es costoso mantener una conexión separada para cada par de procesos 
de comunicación, la capa subyacente podría decidir usar la misma conexión para 
múltiples conversaciones sin relación entre si, siempre y cuando esta 
\textbf{multiplexión} y demultiplexión se realice de manera transparente, cualquier 
capa la podrá utilizar. La multiplexión se necesita en la capa física, donde múltiples 
conversaciones comparten un número limitado de circuitos físicos.

\par Cuando hay múltiples rutas entre el origen y el destino se debe elegir la mejor o 
las mejores entre todas ellas, este tema se llama \textbf{enrutamiento}.

\subsection{Comparación entre servicio orientado a conexión y servicio sin conexión}
\par Normalmente una capa puede ofrecer distintos tipos de servicio a las capas arriba 
suyo. El servicio orientado a la conexión, el usuario del servicio primero establece una 
conexión, la utiliza y luego la abandona. Una conexión funciona como un tubo: el 
emisor empuja objetos en un extremo y el receptor los toma en el otro extremo. Se 
conserva el orden en que esos objetos salen y llegan.
\par En el servicio no orientado a la conexión cada mensaje lleva completa la dirección 
de destino y cada uno se enruta a través del sistema, independientemente de los 
demás. Algunos servicios son confiables en el sentido que nunca pierden datos, pero 
por lo general en un servicio confiable el receptor confirma la recepción de cada 
mensaje. Al servicio no orientado a la conexión no confiable, es decir sin confirmación 
de recepción, se lo conoce como servicio de datagramas. 
\par A veces se desea no tener que establecer una conexión para enviar un mensaje 
corto, pero la confiabilidad es esencial. Para estas aplicaciones se usa el servicio de 
\textbf{datagramas confirmados}. En el servicio de \textbf{solicitud-respuesta} el 
emisor transmite un solo datagrama con una solicitud y luego el receptor envía la 
respuesta al estilo del modelo cliente-servidor.


\section{Modelos de referencia}

\subsection{El modelo de referencia OSI}

\subsubsection{La capa de enlace de datos}
\par La tarea principal de la capa de enlace de datos es transformar un medio de 
transmisión puro en una línea de comunicación que aparezca libre de errores de 
transmisión. El emisor fragmenta los datos de entrada en \textbf{tramas de datos}, y 
transmite las tramas de manera secuencial. Si el servicio es confiable, el receptor 
confirma la recepción correcta de cada trama devolviendo una \textbf{trama de 
confirmación de recepción}.
\par Otro problema atacado es como hacer que un emisor rápido no sature de datos a 
un receptor lento: mecanismo de regulación de tráfico. Con frecuencia esta regulación 
de flujo y el manejo de errores están integrados. Las redes de difusión además 
consideran como controlar el acceso a un canal compartido. La subcapa de control de 
acceso al medio se ocupa de esto.

\subsubsection{La capa de red}
\par La capa de red controla las operaciones de la subred. Hay que determinar cómo se enrutan los paquetes desde su origen a su destino. Si hay demasiados paquetes en la subred al mismo tiempo, se interpondrán en el camino unos y otros lo que hará que se formen cuellos de botella, la capa de red se ocupa de controlar esta congestión.
\par Cuando un paquete tiene que viajar de una red a otra para llegar a destino pueden surgir varios problemas; el direccionamiento de la segunda red podría ser distinto, la segunda podría no aceptar el paquete porque es demasiado largo, los protocolos podrían ser distintos, etc. La capa de red resuelve estos problemas.

\subsection{El modelo de referencia TCP/IP}

Se eligió una red de conmutación de paquetes basada en una capa de interred no 
orientada a la conexión.
– El trabajo de la capa de interred es permitir que los hosts inyecten paquetes dentro de cualquier red y que estos viajen a su destino de manera independiente.
– Tal vez lleguen en un orden distinto al cual fueron enviados, en cuyo caso las capas mas altas deberán ordenarlos, si se desea una entrega ordenada.
– La capa de interred define un paquete de formato y protocolo oficial llamado IP (protocolo de internet).
– Direcciones IP
• 4 números entre 0 y 255 separados por ‘.’ .
• P. ej. 200, 45.191.35
• El trabajo de la capa de interred es entregar paquetes IP al destinatario.
– El enrutamiento de paquetes es el aspecto principal, con el propósito de evitar la congestión.

 La capa arriba de la capa interred es la capa de transporte, la cual esta diseñada para permitir que las entidades iguales en los hosts de origen y destino puedan llevar a cabo una conversación.
 Se tienenn dos protocoles de transporte
– TCP es confiable, orientado a la conexión y permite que un flujo de bytes que se origina en una máquina se entregue sin errores en cualquier otra máquina en la interred.
 TCP divide el flujo en de bytes entrantes en mensajes discretos y pasa cada uno de ellos a la capa de interred.
 En el destino el proceso TCP receptor reensambla en el flujo de salida los mensajes recibidos.
 TCP también maneja el control de flujo para que un emisor rápido no sature con mas mensajes que los que puede manejar a un receptor lento.
– UDP es un protocolo no confiable y no orientado a la conexión, para aplicaciones que no desean el control de flujo ni la secuenciación de mensajes.
 Tiene un amplio uso en consultas de solicitud-respuesta de tipo cliente-servidor en un solo envío y en aplicaciones de transmisión de voz y video.

La capa de aplicación contiene todos los protocolos de nivel mas alto: terminal virtual (TELNET), transferencia de archivos (FTP), correo electrónico (SMTP), para resolución de nombres de host en sus direcciones de red (DNS), para páginas web (HTTP).

\subsection{Una crítica al modelo de referencia TCP/IP}

Problemas:
– No se distingue entre servicio, interfaz y protocolo.
 O sea no se distingue bien entre especificación e implementación.
– No es un modelo general: no esta ajustado para describir ninguna pila de protocolos mas que TCP/IP.
– No se mencionan las capas físicas y de enlace de datos
– Protocolos altamente entrincherados y difíciles de remplazar.

\section{Redes de ejemplo}

\subsection{Internet}
\par Internet es un inmenso conjunto de redes diferentes, que usan ciertos 
protocolos comunes y proporcionan ciertos servicios comunes. A este sistema nadie 
lo planeo y nadie lo controla. 
\par Los protocolos TCP e IP están preparados para manejar comunicaciones por 
interredes. Se desarrollo una interfaz de programación para la red llamada sockets 
de Berkley.

– Luego se creo el DNS (sistema de nombres de dominios) para organizar máquinas 
dentro de dominios y resolver nombres de hosts en direcciones IP.
– Una máquina esta en Internet si ejecuta una pila de protocolos TCP/IP, tiene una 
dirección IP y puede enviar paquetes a todas las demás maquinas de Internet.

Muchas máquinas pueden llamar a un proveedor de servicios de Internet mediante 
un modem, recibir direcciones IP temporales y enviar paquetes a otros hosts de 
Internet.

\subsection{El modelo utilizado en este libro}
\section{Resumen}

\par Las redes de computadoras tienen muchos usos, tanto para empresas como para 
individuos, en el hogar y en movimiento. Las empresas usan redes de computadoras 
para compartir la información corporativa, por lo general mediante el modelo cliente-
servidor en donde las computadoras de los empleados actúan como clientes que 
acceden a poderosos servidores en la sala de máquinas. Para los individuos, las redes 
ofrecen acceso a una variedad de recursos de información y entretenimiento, así como 
una manera de comprar y vender productos y servicios. Con frecuencia los individuos 
acceden a Internet por medio de sus proveedores de teléfono o cable en el hogar, 
aunque cada vez se utiliza más el acceso inalámbrico para laptops y teléfonos. Los 
avances tecnológicos permiten nuevos tipos de aplicaciones móviles y redes con 
computadoras integradas a los electrodomésticos y demás dispositivos para el 
consumidor. Los mismos avances generan cuestiones sociales tales como las 
relacionadas con la privacidad.
\par En términos generales, podemos dividir a las redes en LAN, MAN, WAN e 
interredes. Por lo general las redes LAN cubren todo un edificio y operan a velocidades 
altas. Las redes MAN comúnmente cubren toda una ciudad. El sistema de televisión 
por cable es un ejemplo, ya que ahora muchas personas lo utilizan para acceder a 
Internet. Las redes WAN pueden cubrir un país o continente. Algunas de las 
tecnologías utilizadas para construir estas redes son de punto a punto (como un 
cable), mientras que otras son de difusión (como las redes inalámbricas). Las redes se 
pueden interconectar con enrutadores para formar interredes, de las cuales Internet es 
el ejemplo más grande y popular. Las redes inalámbricas, como las redes LAN 802.11 
y de telefonía móvil 3G, también se están volviendo muy populares.
\par El software de red se basa en los protocolos, que son reglas mediante las cuales 
los procesos se comunican entre sí. La mayoría de las redes soportan jerarquías de 
protocolos, en donde cada capa proporciona servicios a la capa inmediata superior y 
los aísla de los detalles sobre los protocolos que se utilizan en las capas inferiores. Por 
lo general las pilas de protocolos se basan en el modelo OSI o en el modelo TCP/IP. 
Ambos modelos tienen capas de enlace, red, transporte y aplicación, pero difieren en 
las otras capas. Los aspectos de diseño incluyen: confiabilidad, asignación de recursos, 
crecimiento, seguridad, etc.
\par Las redes proveen varios servicios a sus usuarios. Estos servicios pueden variar, 
desde la entrega de paquetes sin conexión de mejor esfuerzo hasta la entrega 
garantizada orientada a conexión. En algunas redes se proporciona servicio sin 
conexión en una capa y servicio orientado a conexión en la capa inmediata superior.
Entre las redes más conocidas están: Internet, la red de telefonía móvil 3G y las redes 
LAN 802.11. Internet evolucionó de ARPANET, a la que se agregaron otras redes para 
formar una interred. En realidad la Internet de la actualidad es una colección de 
muchos miles de redes que utilizan la pila de protocolos TCP/IP. La red de telefonía 
móvil 3G proporciona acceso inalámbrico y móvil a Internet, con es LAN inalámbricas 
basadas en el estándar IEEE 802.11 se implementan en muchos hogares y cafés; 
pueden proporcionar conectividad a velocidades en mayores 100 Mbps. También están 
surgiendo nuevos tipos de redes, como las redes de sensores integradas y las redes 
basadas en tecnología RFID.
Para permitir que varias computadoras se comuniquen entre sí se requiere una gran 
cantidad de estandarización, tanto en hardware como en software. Las organizaciones 
tales como ITU-T, ISO, IEEE e IAB administran distintas partes del proceso de 
estandarización.




\chapter{LA CAPA DE RED}
La capa de red se encarga de llevar los paquetes todo el camino, desde el origen hasta el destino. Para llegar al destino tal vez sea necesario realizar muchos saltos en el camino por enrutadores intermedios. Esta función ciertamente contrasta con la de la capa de enlace de datos, cuya única meta es mover tramas de un extremo del cable al otro. Por lo tanto, la capa de red es la capa más baja que maneja la transmisión de extremo a extremo.
\par Para lograr sus objetivos, la capa de red debe conocer la topología de la red (es
decir, el conjunto de todos los enrutadores y enlaces) y elegir las rutas apropiadas
incluso para redes más grandes. También debe tener cuidado al escoger las rutas para
no sobrecargar algunas de las líneas de comunicación y los enrutadores, y dejar
inactivos a otros. Por último, cuando el origen y el destino están en redes diferentes, ocurren nuevos problemas. La capa de red es la encargada de solucionarlos. En este capítulo estudiaremos todos estos temas y los ilustraremos, principalmente mediante el uso de Internet y su protocolo de capa de red, IP.

\section{Aspectos de diseño de la capa de red}
\subsection{Servicios proporcionados a la capa de transporte}

La capa de red proporciona servicios a la capa de transporte en la interfaz entre la 
capa de red y de transporte. Una pregunta importante es qué tipo de servicios 
proporciona precisamente la capa de red a la capa de transporte. Hay que diseñar los 
servicios de manera cuidadosa, con los siguientes objetivos en mente:
	\begin{itemize}
		\item Los servicios deben ser independientes de la tecnologia del 			
		enrutador.
		\item La capa de transporte debe estar aislada de la cantidad, tipo y topología 
		de los enrutadores presentes.
		\item Las direcciones de red disponibles para la capa de transporte deben usar 
		un plan de numeracin uniforme, incluso a traves de redes LAN y WAN.
	\end{itemize}
\par Dadas estas metas, los diseñadores de la capa de red tienen mucha libertad para 
escribir especificaciones detalladas de los servicios que se ofrecerán a la capa de 
transporte. Con frecuencia esta libertad degenera en una batalla campal entre dos 
bandos en conflicto. La discusión se centra en determinar si la capa de red debe 
proporcionar un servicio orientado a conexión o un servicio sin conexión.
\par Estos dos bandos son:
	\begin{enumerate}
		\item La comunidad de internet
		\begin{itemize}\itemsep=0pt
			\item La tarea del enrutador es solo mover bits de un lado a otro.
			\item La subred es inherentemente inestable. Los hosts deben efectuar el 
			control de errores y el control de flujo.
			\item No debe efectuarse ningún ordenamiento de paquetes.
			\item Cada paquete se transportará de manera independiente a sus 
			antecesores.
			\end{itemize}
		\item Las compañías telefónicas:
		\begin{itemize}\itemsep=0pt
			\item La subred debe proporcionar un servicio confiable, orientado a la
conexión..
			\item La subred es inherentemente inestable. Los hosts deben efectuar el 
			control de errores y el control de flujo.
			\item La calidad del servicio es el factor dominante, sin conexiones en la 
			subred tal calidad es muy difícil de alcanzar, especialmente para el tráfico de 
			tiempo real como la voz y el video.
		\end{itemize}
	\end{enumerate}
\par Los dos bandos se ejemplifican con Internet y las redes ATM.

\subsection{Implementación del servicio sin conexión}
	\begin{itemize}\itemsep=0pt
			\item Los paquetes se colocan individualmente en la subred y se enrutan de
manera independiente.  Por eso debe levar una dirección de destino completa. 
			\item \textbf{Datagramas} = paquetes
			\item \textbf{Subred de Datagramas} = subred
			\item Tabla interna de un enrutador
			\par Entrada de la tabla interna = (destino, línea de salida)
			\par Cuando llega un paquete: Se lo almacena y se comprueba que llegó bien; se reenvía al destino de acuerdo con la tabla del enrutador.
			\item Los enrutadores requieren la capacidad de reemplazar identificadores de conexión en los paquetes salientes, ya que podria darse el caso de que un host H1 inicie una conexión con identificador 1; luego otro host H3 inicia conexión con identificador 1, y ambos hosts están conectados al mismo enrutador A.
			\end{itemize}
	\par Ahora veamos como funciona una red de datagramas. Suponga que el proceso P1 de la figura tiene un mensaje largo para P2. Dicho proceso entrega el mensaje a la capa de transporte y le indica a ésta que lo envíe al proceso P2 en el host H2. El código de la capa de transporte se ejecuta en H1, por lo general dentro del sistema operativo. Dicho código agrega un encabezado de transporte al frente del mensaje y entrega el resultado a la capa de red, que quizá sólo sea otro procedimiento dentro del sistema operativo.
\begin{center} 
	\includegraphics[width=8cm, height=6cm]{./imagenes/norientado.png} 
\end{center}

\par Problema:  
\par IP es el ejemplo dominante de un servicio de red sin conexión. Cada paquete 
transporta una dirección IP de destino que los enrutadores usan para reenviar cada 
paquete por separado. Las direcciones son de 32 bits en los paquetes IPv4 y de 128 
bits en los paquetes IPv6.

\subsection{Implementación del servicio orientado a conexión}
	\begin{itemize}\itemsep=0pt
			\item \textbf{Conexiónes o circuitos virtuales (CV)}
			\item \textbf{Subred de Circuitos Virtuales} = subred
			\item Evitar la necesidad de elegir una nueva ruta para cada paquete enviado. 
			La ruta de una conexión se almacena en tablas en los enrutadores, esta ruta se 
			usa para todo el tráfico que fluye a través de la conexión.
			\item Cada paquete lleva un identificador de CV.
			\item Liberación de conexión: se termina el CV
			\item Se paga el precios del espacio de tabla en los enrutadores. El uso de CVs 
			requiere una fase de configuración que consume tiempo y recursos.
	\end{itemize}

\begin{center} 
	\includegraphics[width=8cm, height=6cm]{./imagenes/orientado.png} 
\end{center}

\par En algunos contextos, a este proceso se le conoce como conmutación mediante 
etiquetas. MPLS (MultiProtocol Label Swithching) es un ejemplo de servicio de red 
orientado a conexión. Se utiliza dentro de las redes de ISP en Internet, en donde los 
paquetes IP se envuelven en un encabezado MPLS que tiene un identificador de 
conexión o etiqueta de 20 bits.
	
\subsection{Comparación entre las redes de circuitos virtuales y las redes de datagramas}
	Dentro de la red existen ventajas y desventajas entre los circuitos virtuales y los 
	datagramas. Una de ellas tiene que ver con el tiempo de configuración y el tiempo de 
	análisis de la dirección. El uso de circuitos virtuales requiere una fase de 
	configuración que necesita tiempo y recursos. Sin embargo, una vez que se paga 
	este precio, es fácil averiguar qué hacer con un paquete de datos en una red de 
	circuitos virtuales: el enrutador sólo usa el número de circuito para buscar en una 
	tabla y encontrar hacia donde va el paquete. En una red de datagramas no se 
	requiere configuración, pero se requiere un procedimiento más complicado para 
	localizar la entrada correspondiente al destino.

	\begin{center} 
		\includegraphics[width=10cm, height=6cm]{./imagenes/comparacion.png}
	\end{center}
	
	\begin{itemize}
		\item Si se cae un enrutador en CV: se pierde su memoria, y todos los CV que 
		pasan por el tendrán que abortarse.
		\item Si se cae un enrutador de datagramas: solo sufrirán los usuarios cuyos 
		paquetes estaban encolados en el enrutador en el momento de la falla, 
		dependiendo de si había confirmado o no su recepción, tal vez ni siquiera todos 
		ellos.
	\end{itemize}


\section{Algoritmos de enrutamiento}
	\par El algoritmo de enrutamiento es aquella parte del software de la capa de red 
	responsable de decidir por cuál línea de salida transmitirá un paquete entrante. Si la 
	red usa datagramas de manera interna, esta decisión debe tomarse cada vez que 
	llega un paquete de datos, dado que la mejor ruta podría haber cambiado desde la 
	última vez. Si la red usa circuitos virtuales internamente, las decisiones de 
	enrutamiento se toman sólo al establecer un circuito virtual nuevo. En lo sucesivo, 
	los paquetes de datos simplemente siguen la ruta ya establecida. Este último caso a 
	veces se llama enrutamiento de sesión, dado que una ruta permanece vigente 
	durante toda una sesión.
	\par En ocasiones es útil distinguir entre el enrutamiento, que es el proceso que 
	consiste en tomar la decisión de cuáles rutas utilizar, y el reenvío, que consiste en la 
	acción que se toma cuando llega un paquete. Podemos considerar que un enrutador 
	tiene dos procesos internos. Uno de ellos maneja cada paquete conforme llega, y 
	después busca en las tablas de enrutamiento la línea de salida por la cual se enviará. 
	Este proceso se conoce como reenvío. El otro proceso es responsable de llenar y 
	actualizar las tablas de enrutamiento. Es ahí donde entra en acción el algoritmo de 
	enrutamiento.
	
	\par Propiedades que todo algoritmo de enrutamiento debe poseer:
		\begin{itemize}
			\item \textbf{Robustez:} una vez que una red entra en operación, deberá
			funcionar 			
			continuamente durante años. Durante ese período habrá fallas de hardware y de 
			software de todo tipo. Los hosts, enrutadores y líneas fallarán en forma 
			repetida y la topología cambiará muchas veces.
			\par El algoritmo de enrutamiento debe ser capaz de manejar los cambios de 
			topología y tráfico sin requerir que aborten todas las actividades en todos los 
			hosts y el reinicio de la red con cada caída de un enrutador.
			\item \textbf{Optimización:} por un lado se intenta minimizar el 
			retardo medio de los paquetes, por otro aumentar al máximo la velocidad real 
			de transporte en la red. 
			\par Estas dos metas están en conflicto. Como término medio muchas redes 
			intentan minimizar el número de saltos que tiene que dar un paquete.
			La reducción de la cantidad de saltos reduce el retardo y también el consumo 
			de ancho de banda, lo que a su vez mejora la velocidad real de transporte.
			\item \textbf{Equidad:} implica que todos los hosts deben poder usar la subred 
			ya sea para enviar o para recibir.
			\par La equidad y la optimización son con frecuencia metas contradictorias. Por 
			ende se requiere de un punto medio entre la eficiencia global y la equidad hacia 
			las conexiones individuales.
			\item \textbf{Sencillez:} apenas requiere comentarios. Es algo que todos los 
			algoritmos de enrutamiento deberían tener. 
			\item \textbf{Estabilidad:} también es una meta importante para el algoritmo 
			de enrutamiento. Existen algoritmos de enrutamiento que nunca convergen 
			hacia un conjunto de rutas fijo, sin importar el tiempo que permanezcan en 
			operación. Un algoritmo estable alcanza el equilibrio y lo conserva. Además 
			debe converger con rapidez, ya que se puede interrumpir la comunicación hasta 
			que el algoritmo de enrutamiento haya llegado a un equilibrio.
		\end{itemize}
		
		\par Los algoritmos de enrutamiento pueden agruparse en dos clases: 
		\begin{enumerate}
		
			\item  \textbf{\emph{Los algoritmos no adaptativos: }} no basan sus 
			decisiones de enrutamiento en mediciones o estimaciones del tráfico y la 
			topología actuales.
			\begin{itemize}
				\item La decisión de qué ruta se usará para ir de I a J se toma por 
				adelantado.
				\item A esto se lo conoce como enrutamiento estático.
				\item Ejemplos: enrutamiento de caminos más cortos, inundación.
			\end{itemize}
			
			\item \textbf{\emph{Los algortimos adaptativos:}} cambian sus decisiones de 
			enrutamiento para reflejar los cambios de topología, y por lo general también 
			del tráfico.
			\par Los algoritmos adaptivos difieren en:
			\begin{itemize}
				\item El lugar donde obtienen su información, localmente en los enrutadores 
				adyacentes o en todos los enrutadores.
				\item El momento de cambio de sus rutas (i.e. de sus tablas de 
				enrutamiento). Hay varias opciones, ellas son: cada cierta cantidad de 
				segundos, cuando cambia la carga, o cuando cambia la topología.
				\item La métrica usada para la optimización: distancia, número de saltos, 
				tiempo estimado de tránsito, etc.
			\end{itemize}
			\par Ejemplos: enrutamiento de vector de distancia, enrutamiento de estado de 
			enlace.		
		\end{enumerate}

\subsection{Principio de optimización}
	\par Establece que si un enrutador \textit{J} está en ruta óptima 
	del enrutador \textit{I} al enrutador \textit{K}, entonces la ruta óptima de \textit{J}
	a \textit{K} también está en la misma ruta.
	\par Como consecuencia directa del principio de optimización, podemos ver que el 
	grupo de rutas óptimas de todos los orígenes a un destino dado forman un árbol con 
	raíz en el destino. Dicho árbol se conoce como \textit{árbol sumidero} y se ilustra en 
	la figura, donde la métrica de distancia es el número de saltos. El objetivo de todos 
	los algoritmos de enrutamiento es descubrir y usar los árboles sumidero para todos 
	los enrutadores.
	
	\begin{center}
		\includegraphics[width=10cm, height=6cm]{./imagenes/optimalidad.png}
	\end{center}

	\par Por ende la meta de todos los algoritmos de enrutamiento es descubrir y utilizar 
	los árboles sumideros de todos los enrutadores.
	
	\par Comenzaremos estudiando algoritmos estáticos, los mismos no son muy 
	buenos, pero veremos que pequeñas variantes de ellos son usados por los algoritmos 
	adaptivos.

\subsection{Algoritmo de la ruta más corta}
	\par La idea es construir un grafo de la red, en donde cada nodo del grafo 
	representa un enrutador y cada arco del grafo representa una línea o enlace de 
	comunicaciones. Para elegir una ruta entre un par específico de enrutadores, el 
	algoritmo simplemente encuentra la ruta más corta entre ellos en el grafo.

	\par Una manera de medir la longitud de una ruta es mediante el número de saltos. 
	Otra métrica es la distancia geográfica en kilómetros, etc. En el caso más general, las 
	etiquetas de los arcos podrían calcularse como función de la distancia, ancho de 
	banda, tráfico medio, costo de comunicación, longitud media de las colas, retardo 
	medio, y otros factores.

	\par Se conocen varios algoritmos para calcular la ruta más corta entre dos nodos de 
	un grafo. Uno de éstos se debe a Dijkstra.


	\par \textbf{Algoritmo de Dijktra:}
		\begin{itemize}
			\item Calculamos la ruta más corta posible entre \emph{s} y \emph{t}
			comenzando por el nodo de destino \emph{t}.
			\item El algoritmo calcula un árbol sumidero en la subred.
			\item Cada nodo se etiqueta con su distancia al nodo de origen a través de la 	
			mejor ruta conocida (al comienzo todos los nodos tienen etiqueta <). Mientras 
			avanza el algoritmo las etiquetas pueden cambiar reflejando mejores rutas.
 			\item Una etiqueta puede ser tentativa o permanente. Inicialmente todas las 
 			etiquetas son tentativas. Cuando se descubre que una etiqueta representa la 
 			ruta más corta del origen a ese nodo, se vuelve permanente y no cambia más.
			\item Se tiene una iteración para la cua lsiempre hay un nodo de trabajo. Ese 
			nodo de trabajo es el nodo tentativo con la menor etiqueta calculado en el paso 
			de iteración anterior (Inicialmente el nodo de trabajo es \emph{t}).
			
			En cada paso de la iteración se actualizan las etiquetas de los nodos tentativos 
			siempre y cuando el nodo de trabajo ayude a encontrar una ruta mejor.
		\end{itemize}

	\begin{center}
	\includegraphics[width=8cm, height=5cm]{./imagenes/dijktra.png} 

	\includegraphics[width=10cm, height=6cm]{./imagenes/caminos.png}
	\end{center}

\subsection{Inundación}
	\par Otro algoritmo estático es la inundación, en la que cada paquete de entrada se 
	envía por cada una de las líneas de salida, excepto aquella por la que llegó.
    Esta idea tiene un problema, la inundación genera grandes cantidades de paquetes 
    duplicados; a menos que se tomen algunas medidas para limitar el proceso. Veamos 
    algos de estas ideas:

	\begin{itemize}
		\item Solución 1: integrar un contador de saltos en el encabezado de cada 
		paquete, que disminuya con cada salto y el paquete se descarte cuando el 
		contador llega a 0. Lo ideal es inicializar el contador de saltos a la longitud de la 
		ruta entre el origen y el destino. Si el emisor desconoce el tamaño de la ruta, 
		puede inicializar el contador al peor caso, es decir, al diámetro total de la subred.
		
		\item Solución 2: llevar un registro de los paquetes difundidos para evitar 
		enviarlos por segunda vez. Hacer que el enrutador de origen ponga un número de 
		secuencia en cada paquete que recibe de sus hosts. Para cada enrutador de origen 
		hay una lista con los números de secuencia originados en ese enrutador que ya ha 
		visto. Si un paquete de entrada está en la lista, no se difunde.

		Para evitar que las listas crezcan sin límites podemos agregar una columna 
		contador que indica el mayor número de secuencia tal que llegaron paquetes con 
		todos los numeros de secuencia anteriores desde ese enrutador de origen.
		
		\item Solución 3: Una variación de la inundación, un poco mas práctica, es la 
		inundación selectiva. Los enrutadores no envían cada paquete de entrada por 
		todas las líneas, sino solo por aquellas que van aproximadamente en la dirección 
		correcta.

		A nivel de información, se necesita saber en qué  dirección va cada línea y en qué 
		dirección está el destino.
		
		\par La inundación no es práctica en la mayoría de las aplicaciones, pero tiene
		algunos usos, por ejemplo, en aplicaciones militares, en aplicaciones distribuidas 
		de bases de datos. La inundación siempre elige la ruta más corta posible porque 
		escoge en paralelo todas las rutas posibles. En consecuencia ningún otro 
		algoritmo puede producir un retardo más corto (si ignoramos la sobrecarga 
		generada por el proceso de inundación mismo).
		
	\end{itemize}
		
\subsection{Enrutamiento por vector de distancia}

	\par 	Existen dos algoritmos dinámicos que son los más populares: el enrutamiento 
	por vector de distancia y el enrutamiento por estado del enlace. En esta sección 
	veremos el primer algoritmo, en la siguiente estudiaremos el segundo.
	\par En el enrutamiento por vector de distancia, cada enrutador mantiene una tabla 
	de enrutamiento indizada por cada enrutador de la red. Esta entrada consta de dos 
	partes:
	\begin{itemize}
			\item La línea preferida de salida a usar para ese destino
			\item Una estimación del tiempo o distancia a ese destino. 
	\end{itemize}
	\par La distancia se podría medir como la cantidad de saltos, o se podría usar otra 
	métrica, como vimos al calcular las rutas más cortas. 
	\par 	Estas tablas se actualizan intercambiando información con los vecinos. Este 
	algoritmo se usó en Internet con el nombre \textbf{RIP}.
	
	\par Se supone que el enrutador conoce la “distancia” a cada uno de sus vecinos.
		\begin{itemize}
			\item Si la métrica es de saltos, la distancia es un salto.
			\item Si la métrica es la longitud de la cola, el enrutador simplemente examina 
			cada cola.
			\item Si la métrica es el retardo, el enrutador puede medirlo con paquetes de 
			ECO que el receptor simplemente marca con la hora y los regresa tan rápido 
			como puede.
		\end{itemize}
	\par Suponga que el retardo se usa como métrica y que el enrutador conoce el 
	retardo a cada uno de sus vecinos. Una vez cada \textit{T} mseg, cada enrutador 
	envía a todos sus vecinos una lista de sus retardos estimados a cada destino.
	También recibe una lista similar de cada vecino. Imagine que la tabla
	\textit{$T_{x}$} acaba de llegar del vecino \textit{X}, en donde \textit{$X_{i}$} es 
	la 	estimación respecto al tiempo que le toma llegar al enrutador \textit{i}. Si el 	
	enrutador sabe que 	el retardo a 	\textit{X} es de \textit{$m_{x}$} mseg, también 
	sabe que puede llegar al enrutador \textit{i} a través de \textit{X} en 
	\textit{$X_{i}$} $+$ \textit{$m_{i}$} mseg. Al efectuar este cálculo para cada 
	vecino, un enrutador puede encontrar la estimación que parezca ser la mejor y usar 
	esa estimación, así como el enlace correspondiente, en su \textbf{nueva tabla de 
	enrutamiento}. Cabe mencionar que en este cálculo no se utiliza la antigua tabla de 
	enrutamiento.

	\par El enrutamiento por vector reacciona con rapidez a las buenas noticias, pero 
	con lentitud ante las malas. Considere un enrutador cuya mejor ruta al destino 
	\textit{X} es larga. Si en el siguiente intercambio el vecino \textit{A} informa 
	repentinamente un retardo corto a \textit{X}, el enrutador simplemente se conmuta 
	a modo de usar la línea a A para enviar tráfico hasta X.
Supongamos que la métrica de retardo es el numero de saltos.
 Las buenas noticias se difunden a razón de un salto por intercambio.
 En una subred cuya ruta mayor tiene una longitud de N saltos, en un lapso de N intercambios todo el mundo sabrá sobre las líneas y enrutadores recientemente revividos.
La razón de porque las malas noticias viajan con lentitud es: ningún enrutador jamás tiene un valor mayor en más de una unidad que el mínimo de todos sus vecinos.
Gradualmente todos los enrutadores elevan cuentas hacia el infinito, pero el número de intercambios requeridos depende del valor numérico usado para el infinito.
Si la métrica usada es el número de saltos, es prudente hacer que el infinito sea igual a la ruta más larga más 1.

Si la métrica es el retardo de tiempo no hay un límite superior
bien definido,
se necesita un valor alto para evitar que una ruta con un retardo grande sea tratada como si estuviera desactivada.
Este es el problema de la cuenta hasta el infinito.
Se han hecho varios intentos para resolverlo, pero ninguno funciona bien
en general.
La esencia del problema consiste en que cuando X indica Xi a E, E no tiene forma de saber si el destino i está en alguna ruta en funcionamiento.

\subsection{Enrutamiento por estado del enlace}
	\par La idea detrás del enrutamiento por estado del enlace es bastante simple y 
	se puede enunciar en cinco partes. Cada enrutador debe realizar lo siguiente para 
	hacerlo funcionar:

	\begin{enumerate}
		\item Descubrir a sus vecinos y conocer sus direcciones de red: esto lo realiza 
		enviando un paquete HELLO especial a cada línea punto a punto. Se espera que 
		el 	enrutador del otro extremo regrese una respuesta indicando quién es. Estos
		nombres deben ser globalmente únicos.

		\item Establecer la métrica de distancia o de costo para cada uno de sus vecinos:
		el AEEE requiere que cada enrutador tenga una idea razonable del retardo a cada 
		uno de sus vecinos. Una forma de determinarlo es enviar un paquete ECHO 
		especial a través de la línea, una vez que llegue al otro extremo, éste debe 
		regresarlo inmediatamente.

		\par Si se mide el tiempo de ida y vuelta y se divide por $2$, el enrutador emisor 
		puede tener una idea razonable del retardo. Pero esto tiene un problema, ya que 
		el algoritmo asume de manera implícita que los retardos son simétricos, lo cual no 
		siempre es el caso.

		\par Un aspecto importante es si se debe tener en cuenta la carga al medir el 
		retardo. Para considerar la carga, el temporizador debe iniciarse cuando el paquete 
		ECHO se ponga en la cola. Para ignorar la carga, el temporizador debe iniciarse 
		cuando el paquete ECHO alcance el frente de la cola.
		
		\par Cuando un enrutador puede escoger entre dos líneas con el mismo ancho de 
		banda, una con carga alta continua y otra sin ella, considerará como ruta más 
		corta la de la línea sin carga. Esta selección resultará en un mejor desempeño. 		
		Desgraciadamente también hay un argumento en contra de la inclusión de la carga 
		en el cálculo del retardo.

		\item Construir un paquete que indique todo lo que acaba de aprender: Cada 
		enrutador construye un paquete des estado de enlace (LSP) que contiene todos 
		los datos:
		\begin{itemize}
			\item Identidad del emisor
			\item Numero de secuencia
			\item Edad
			\item Lista de (vecino, retardo al vecino)
		\end{itemize}

		\par los paquetes deben ser construirlos de manera periódica, es decir, a 
		intervalos regulares o cuando ocurra un evento significativo, como la caída o la 
		reactivación de la línea o de un vecino, o el cambio apreciable de sus propiedades.

		\item Enviar este paquete a todos los demás enrutadores y recibir paquetes de 		
		ellos: la parte más complicada del algoritmo es la distribución confiable de los 
		paquetes de estado del enlace.
		
		\par La idea fundamental es usar inundación para distribuir los paquetes de 
		estado 
		del enlace, llevando un registro de los paquetes difundidos. A fin de mantener 
		controlada la inundación, cada paquete contiene un número de secuencia que se 
		incrementa con cada paquete nuevo enviado (desde su enrutador de origen).
		\par Los enrutadores llevan el registro de todos los pares (enrutador de origen, 
		secuencia) que ven. Para cada enrutador de origen el paquete recibido con 
		número de secuencia más grande es el que importa, los anteriores no.

		\item Calcular la ruta más corta a todos los demás enrutadores.
	\end{enumerate}



\subsection{Enrutamiento jerárquico}
\subsection{Enrutamiento por difusión}
\section{Algoritmos de control de congestión}
\subsection{Métodos para el control de la congestión}
\subsection{Enrutamiento consciente del tráfico}
\subsection{Control de admisión}
\subsection{Regulación del tráfico}
\subsection{Desprendimiento de carga}

\section{La capa de internet}
	\subsection{El protocolo IP versión 4}
	\subsection{Direcciónes IP}


\subsection{Protocolos de control de Internet}


%LIsta
\subsubsection{ARP: Protocolo de Resolución de Direcciones}

	\par Aunque en internet una máquina tiene una o más direcciones IP, estas no pueden usarse para enviar paquetes debido a que el hardware de la capa de enlace de datos no entiende las direcciones de internet. Hoy día la mayoría de los hosts de las compañías y las universidades se une a una LAN por una tarjeta de red que solo entiende direcciones LAN. Por ejemplo cada tarjeta Ethernet viene provista de fábrica con una dirección Ethernet de 48 bits, las tarjetas envían y reciben tramas basadas en direcciones Ethernet de 48 bits pero no saben nada de direcciones IP.
	
	\par La pregunta ahora es: ¿Cómo se convierten las direcciones IP en direcciones de la capa de enlace de datos, como Ethernet?. La idea sería que el host de origen dé salida a un paquete de difusión hacia Ethernet preguntando: ¿Quién posee una dirección IP w.x.y.z ?. La difusión llegará a cada máquina en Ethernet y cada una verificará su dirección IP. Al host de destino le bastará con responder con su dirección de Ethernet E y de este modo el host de origen aprende que la dirección IP de w.x.y.z está en el host con la dirección de Ethernet E. Casi cada máquina en Internet ejecuta ARP.

	\par La ventaja de usar ARP es la sencillez. Solo se tiene que asignar a cada máquina una dirección IP y decidir respecto de las máscaras de subred. ARP hace el resto.
	
	\par Se pueden hacer optimizaciones para que ARP funcione con más eficiencia.
	
		\begin{itemize}
			\item \underline{Optimización 1:} una vez que una máquina ha ejecutado ARP, guarda el resultado en caso de que en poco tiempo tenga que ponerse de nuevo en contacto con la misma máquina. La próxima vez encontrará la correspondencia en su propia caché, eliminando así la necesidad de una segunda difusión.

			\item \underline{Optimización 2:} en muchos casos el host de destino necesitará devolver una respuesta, forzando también a que se ejecute el ARP para determinar la dirección Ethernet del emisor. Esta difusión de ARP puede evitarse teniendo el host de origen que incluir su correspondencia IP a Ethernet en el paquete ARP. Cuando la difusión de ARP llega al host de destino, se introduce la dirección IP y de Ethernet del origen en el caché del host 2 para su uso futuro.
			
			\item \underline{Optimización 3:} cada máquina difunde su correspondencia cuando arranca, esto se hace mediante un ARP que busca su propia dirección IP. No debe haber una respuesta, pero un efecto lateral de la difusión es hacer una entrada en el caché ARP de todas las máquinas, si llega inesperadamente una respuesta, es que la misma dirección IP se ha asignado a dos máquinas. La más reciente debe avisar y no arrancar.
		\end{itemize}

	\par Para permitir que las asociaciones cambien, por ejemplo, al configurar un host para que use una nueva dirección IP (pero que mantenga su vieja dirección Ethernet), las entradas en la caché ARP deben expirar después de unos cuantos minutos.
	
	\par Cuando el host de origen y el host de destino están en distintas Ethernet LAN 1 y LAN 2 respectivamente separadas por enrutadores, si se usa ARP fallará ya que el host de destino no verá la difusión (los enrutadores no envían difusiones a nivel Ethernet). Veamos este problema con un ejemplo en la siguiente figura.
	
		\begin{center}
			\includegraphics[width=9cm, height=6cm]{./imagenes/arp.png} 
		\end{center}

	\par Viendo la figura de arriba, supongamos que el \textit{host 1} quiere enviar un paquete al \textit{host 4} (192.32.63.8) en la red IE. El \textit{host 1} verá que la dirección IP de destino no está en la red CS. Sabe enviar todo ese tráfico fuera de la red al enrutador, el cual también se conoce como puerta de enlace predeterminada. Por convención, la puerta de enlace predeterminada es la dirección más baja en la red (198.31.65.1). Para enviar una trama al enrutador, el \textit{host 1} debe conocer de todas formas la dirección Ethernet de la interfaz del enrutador en la red CS. Para descubrirla envía una difusión ARP para 198.31.65.1, a partir de la cual aprende E3. Después envía la trama. Los mismos mecanismos de búsqueda se utilizan para enviar un paquete de un enrutador al siguiente, a través de una secuencia de enrutadores en una ruta de Internet.
	
	\par Cuando la placa de red de Ethernet del enrutador recibe esta trama, entrega el paquete al software IP. Sabe con base en las máscaras de red que el paquete se debe enviar a la red IE, en donde alcanzará al \textit{host 4}. Si el enrutador no conoce la dirección Ethernet para el \textit{host 4}, entonces usará ARP de nuevo. Las direcciones Ethernet cambian con la trama en cada red, mientras que las direcciones IP permanecen constantes (puesto que indican las terminales a través de todas las redes interconectadas).
	
%Lista
\subsection{OSPF: un protocolo de enrutamiento de puerta de enlace interior}
	\par Internet se compone de una gran cantidad de \textbf{Sistemas Autónomos}. Cada uno de ellos es manejado por una organización diferente y puede usar su propio algoritmo interno de enrutamiento. Un algoritmo de enrutamiento dentro de un sistema autónomo se llama \textbf{protocolo de puerta de enlace interior (IGP)}; un algoritmo para enrutamiento entre sistemas autónomos se llama protocolo de \textbf{puerta de enlace exterior (EGP)}.

	\par El protocolo de puerta de enlace interior original en internet era un protocolo de vector de distancia (\textit{RIP}). Fue reemplazado en 1979 por un protocolo de estado de enlace. Luego en 1988 se definió un sucesor llamado OSPF (\textbf{Open Shorted Path First}), que se volvió una norma en 1990. Ahora la mayoría de vendedores de enrutadores lo apoyan.
	
	\par OSPF tenía una larga lista de requerimientos por cumplir. El algoritmo se tenía que apoyar en una variedad de métricas de distancia como distancia física, retardo, etc. Tenía que ser un algoritmo dinámico que se adaptara rápida y automáticamente a los cambios en la topología. Debía apoyar el enrutamiento con base en el tipo de servicio. El nuevo protocolo tenía que dirigir el tráfico en tiempo real de una manera y el resto del tráfico de otra.
	
	\par El nuevo protocolo tenía que balancear la carga, dividiéndola en líneas múltiples. La mayoría de los protocolos anteriores enviaba todos los paquetes por la mejor ruta, incluso si había dos rutas buenas.

	\par Se necesitaba apoyo para los sistemas jerárquicos. Había que tratar con enrutadores que se conectan a internet por medio de un túnel.

	\par OSPF soporta tres tipos de conexiones y redes:

		\begin{enumerate}
			\item Las líneas punto a punto exactamente entre dos enrutadores.
			\item Redes de multiacceso con difusión (la mayoría de las LAN).
			\item Redes de multiacceso con muchos enrutadores, cada uno de los cuales se puede comunicar directamente con los otros.
		\end{enumerate}

	\par La siguiente figura muestra un sistema autónomo con los tres tipos de redes. En ella se omiten los hosts, ya que en general no desempeñan ningún papel en OSPF.

		\begin{center}
			\includegraphics[width=8cm, height=5cm]{./imagenes/ospf.png} 
		\end{center}

	\par OSPF abstrae la topología en un \textbf{grafo dirigido} en el que a cada arco se asigna un costo (distancia, retardo, etc.). Una conexión \textit{punto-punto} entre dos enrutadores se representa por un par de arcos, uno en cada dirección, donde sus pesos pueden ser diferentes. Una red de multiacceso de difusión se representa con un nodo
para la red en sí, más un nodo para cada enrutador. Los arcos desde el nodo de la red a los enrutadores tienen peso 0, sin embargo son importantes puesto que sin ellos no habrá una ruta a través de la red.

	\par Luego de la construcción del grafo se utiliza al algoritmo de \textit{Dijkstra} para hacer que cada enrutador calcule la ruta más corta desde sí mismo hacia todos los demás nodos. Se pueden encontrar varias rutas que sean igual de cortas. En este caso, OSPF recuerda el conjunto de rutas más cortas y, durante el envío de paquetes, el tráfico se divide entre ellas. Este proceso ayuda a balancear la carga y se conoce como ECMP (\textbf{Equal Cost MultiPath}).

	\par Muchos de los sistemas autónomos (AS) en Internet son grandes por sí mismos y nada sencillos de administrar. Para trabajar a esta escala, OSPF permite dividir un AS en áreas numeradas, en donde un área es una red o un conjunto de redes contiguas y cada área puede contener varias redes dentro de sí misma. Las áreas no se traslapan, algunos enrutadores no necesitan pertenecer a ningún área. Los enrutadores que están totalmente dentro de un área se llaman \textbf{enrutadores internos}.

	\par Cada Sistema Autónomo tiene un área de \textbf{red dorsal}, llamada área 0. Los enrutadores en esta área se llaman \textbf{enrutadores dorsales}. Todas las áreas se conectan a la red dorsal, posiblemente mediante túneles, de modo que es posible ir desde cualquier área en el AS a cualquier otra área en el AS mediante la red dorsal. En el grafo, un túnel se representa como otro arco más con un costo. Al igual que con otras áreas, la topología de la red troncal no es visible fuera de esta.

	\par Cada enrutador que se conecta a dos o más áreas se llama \textbf{enrutador de borde de área} (\textit{EBA}) y es parte de la red dorsal y a la vez de una o más áreas.

	\par El \textbf{enrutador de borde de sistema autónomo} (\textit{EBSA}) inyecta en el área rutas a destinos externos en otros AS. Las rutas externas aparecen como destinos que pueden ser alcanzados vía un EBSA con algún costo. Una ruta externa puede ser inyectada a uno o más EBSA.

	\begin{center}
			\includegraphics[width=9cm, height=5cm]{./imagenes/ospf2.png} 
		\end{center}
		
	\par Los EBA resumen información de enrutamiento que han aprendido de un área y la hacen disponible en sus avisos de estado de enlace que envían a las otras áreas. Un EBA recibe mensajes de estado de enlace de todos los enrutadores de una de sus áreas A y entonces determina el costo de alcanzar cada red de A. Cuando un EBA envía avisos de estado de enlace a la red dorsal, avisa de los costos de alcanzar las redes del área A, como si estas redes estuvieran directamente conectadas al EBA, esto permite que todos los enrutadores del área dorsal aprendan el costo de alcanzar todas las redes del área A. Cuando un EBA envía avisos de estado de enlace a su red no dorsal, avisa de los costos a alcanzar todas las redes de las otras áreas (no dorsal). Luego todos los enrutadores aprenden a alcanzar todas las redes en el dominio.
	
	\par Cuando se ejecuta OSPF los enrutadores dentro de un área ejecutan el protocolo de estado de enlace, hay paquetes \textbf{Hello}. Los enrutadores dentro de un área intercambian mensajes de estado de enlace periódicamente usando inundación. Estos enrutadores también envían estos mensajes cuando una línea se cae, regresa o su costo cambia. Los mensajes de estado de enlace de enrutadores que no son EBA no dejan el área en el que se originan. Los enrutadores internos a un área no van a conocer detalles acerca de la topología de otras áreas.

	\par Dentro de un área cada enrutador tiene la misma \textbf{base de datos de estado de enlace} (\textit{BDEE}) y ejecuta el mismo algoritmo de la ruta más corta. Su trabajo principal es calcular el camino más corto desde sí mismo a cualquier otro enrutador de su área y red en el AS entero. Un EBA necesita las bases de datos de estado de enlace para todas las áreas a las cuales está conectado y debe correr el algoritmo de Dijkstra para cada área separadamente.


\subsection{BGP: el protocolo de enrutamiento de Puerta de Enlace Exterior}
	\par Los enrutadores de protocolo de puerta de enlace exterior tienen que 
	preocuparse en gran parte por la política. Muchas veces se quiere mantener las 
	políticas privadas; porque los Sistemas Autónomos (SA) compiten entre sí (ej: PSI 
	competidores).	
	\par Las políticas típicas implican consideraciones políticas, de seguridad, o 
	económicas. Algunos ejemplos de posibles restricciones de enrutamiento son:
		\begin{enumerate}
			\item  No transportar tráfico comercial en la red educativa.
			\item Nunca enviar tráfico del Pentágono por una ruta a través de Irak.
			\item Usar TeliaSonera en vez de Verizon porque es más económico.
			\item No usar AT and T en Australia porque el desempeño es pobre.
			\item El tráfico que empieza o termina en Apple no debe transitar por Google.
		\end{enumerate}

	\par Para enrutamiento inter SA encontrar un camino óptimo es prácticamente 
	imposible. Cada SA corre su propio protocolo interno y usa cualquier esquema para 
	asignar métricas a los caminos. Es imposible calcular costos de caminos 
	significativos para caminos que cruzan varios SA.
	\par Enrutamiento inter SA solo avisa alcanzabilidad, por lo tanto, a lo más puedo 
	tener caminos de SA para ir de un origen a un destino.
	
	\par Para el enrutamiento es necesario encontrar algún camino de SA para el destino 
	deseado que es libre de ciclos. Además los caminos deben respetar las políticas de 
	los SA a lo largo del camino. Donde una política significan reglas que se refieren a 
	preferencias de enrutamiento y a limitaciones de enrutamiento.
   \par Los PPEE suelen implementarse sobre enrutadores de borde de sistema 
   autónomos (EBSA), los cuales tienen que hacer una elección de varias rutas a un 
   destino; va a elegir la mejor de acuerdo con sus propias políticas locales y esta va a 
   ser la ruta que avisa. Además le dice a sus vecinos para cada destino, el camino 
   exacto que está usando.
	\par Muchos PSI existen solo para proveer servicios a consumidores (ej: redes 
	hogareñas). Otros PSI ofrecen algo parecido a un servicio dorsal interconectando 
	otros PSI y a veces grandes corporaciones. A menudo varios proveedores se 
	conectan entre sí como un punto único de compañerismo.


\chapter{LA CAPA DE TRANSPORTE}
\par Junto con la capa de red, la capa de transporte es el corazón de la jerarquía de 
protocolos. La capa de red provee una entrega de paquetes punto a punto mediante 
el uso de datagramas o circuitos virtuales. La capa de transporte se basa en la capa 
de red para proveer transporte de datos de un proceso en una máquina de origen a 
un proceso en una máquina de destino, con un nivel deseado de confiabilidad que es 
independiente de las redes físicas que se utilizan en la actualidad. Ofrece las 
abstracciones que necesitan las aplicaciones para usar la red. Sin esta capa, todo el 
concepto de protocolos por capas tendría muy poco sentido.


\section{El servicio de transporte}
\subsection{Servicios que se proporcionan a las capas superiores}
\par La capa de transporte (CT), al igual que a capa de red, provee:
	\begin{itemize}
		\item un servicio confiable a sus usuarios (orientado a la conexión)
		\item un servicio eficiente a sus usuarios (no orientado a la conexión)
	\end{itemize}
	
\par La capa de transporte se ejecuta por completo en las máquinas de los usuarios 
(hosts). El software/hardware de la capa de transporte se llama \textbf{entidad de 
transporte}.

\par Si en una red sin conexión se pierden paquetes, la entidad de transporte puede 
detectar el problema y compensarlo mediante el uso de retransmisiones. Si, en una 
red orientada a conexión, se termina la conexión de manera abrupta, la entidad puede 
establecer una nueva conexión de red con la entidad de transporte remota.
\par El servicio de transporte se ofrece a programadores y usuarios, debe ser fácil de 
usar y no debe exponer cuestiones internas (retransmisiones, fragmentación, etc.)

	\begin{center}
	\includegraphics[width=8cm, height=5cm]{./imagenes/transporte.png} 
	\end{center}

\subsection{Primitivas del servicio de transporte}


\par Para permitir que los usuarios accedan al servicio de transporte, la capa de 
transporte debe proporcionar algunas operaciones a los programas de aplicación; es 
decir, una interfaz del servicio de transporte.

\begin{center}
	\includegraphics[width=11cm, height=5cm]{./imagenes/primitivas.png} 
\end{center}

\par Usaremos el término \textbf{segmento} para indicar los mensajes que se envían 
de una entidad de transporte a otra. Así, los segmentos (intercambiados por la capa 
de transporte) están contenidos en paquetes (intercambiados por la capa de red), y a 
su vez estos paquetes están contenidos en \textbf{tramas} (intercambiadas por la 
capa de enlace de datos).
\par Cuando llega una trama, la capa de enlace de datos procesa el encabezado de la 
trama y, si la dirección de destino coincide para la entrega local, pasa el contenido del 
campo de carga útil de la trama a la entidad de red. Esta úlltima procesa de manera 
similar el encabezado del paquete y después pasa el contenido de la carga útil del 
paquete a la entidad de transporte. 

\begin{center}
	\includegraphics[width=8cm, height=4cm]{./imagenes/segmentos.png} 
\end{center}

\par Durante una conexión entre dos host se confirmará la recepción de cada 
paquete de datos enviado mediante las entidades de transporte, de manera 
transparente para los usuarios de transporte. De la misma forma, las entidades de 
transporte tienen que preocuparse por los temporizadores y las retransmisiones. Los 
usuarios de transporte no se enteran de ningún aspecto de esta mecánica. Para ellos 
una conexión es un conducto de bits confiable: un usuario mete bits en él y por arte 
de magia aparecen en el otro lado, con el mismo orden.

\par Veamos ahora un diagrama de estado para un esquema simple de manejo de 
conexiónes:

\begin{center}
	\includegraphics[width=11cm, height=7cm]{./imagenes/diagrama.png} 
\end{center}


\section{Elementos de los protocolos de transporte}
\par El servicio de transporte se implementa mediante un \textbf{protocolo de 
transporte} entre las dos entidades de transporte. En la capa de transporte se requiere 
el direccionamiento explícito de los destinos, se requieren búferes y control de flujo.

\subsection{Direccionamiento}
\par Cuando un proceso de aplicación desea establecer una conexión con un proceso 
de aplicación remoto, debe especificar a cuáll se conectará. El método que se emplea 
por lo general es definir direcciones de transporte en las que los procesos puedan 
escuchar las solicitudes de conexión. En Internet, estos puntos terminales se 
denominan \textbf{puertos}. Usaremos el término genérico TSAP (Transport Service 
Access Point) para indicar un punto terminal específico en la capa de transporte. Los 
puntos terminales análogos en la capa de red (es decir, direcciones de capa de red) se 
llamen NSAP (Network Service Access Points). Las direcciones IP son ejemplos de 
NSAP.
\par Los procesos de aplicación,tanto clientes como servidores, se pueden enlazar por 
si mismos a un TSAP para establecer una conexión a un TSAP remoto. Estas 
conexiónes se realizan a través de NSAPs en cada host. Los TSAPs sirven para 
distinguir los múltiples puntos terminales de transporte que comparten un NSAP.

\begin{center}
	\includegraphics[width=6cm, height=5cm]{./imagenes/tsap.png} 
\end{center}

\par ¿Cómo sabe un proceso de usuario que un servidor \textbf{\textit{S}} está 
conectado a un determinado TSAP?

\begin{itemize}
	\item \underline{Solución 1:} una posibilidad es que S se ha estado conectando al 
	mismo TSAP durante años y gradualmente todos los usuarios de la red han 
	aprendido esto. En este modelo los servicios tienen direcciones TSAP estables que 
	se listan en archivos en lugares bien conocidos.
	\par Los procesos de usuario frecuentemente desean comunicarse con otros 
	procesos de usuario que solo existen durante un tiempo corto y no tienen una 
	dirección TSAP conocida por adelantado. En el caso de que hubiese muchos 
	procesos de servidor, la mayoría de los cuales se usaran pocas veces sería un 
	desperdicio tenerlos activados a todos escuchando en una dirección TSAP estable 
	todo el día.
	\item \underline{Solución 2:} un esquema alternativo en forma simplificada, es el 
	conocido como \textbf{protocolo inicial de conexión}. Cada máquina que desea 
	ofrecer servicios a usuarios remotos tiene un servidor de procesos especial que 
	actúa como 	proxy de los servidores de menor uso. Este servidor es llamado 
	\textit{inetd} en sistemas UNIX; el mismo escucha en un grupo de puertos al mismo 
	tiempo esperando una solicitud de conexión. Los usuarios potenciales de un 
	servicio comienzan por emitir una solicitud 	\textbf{CONNECT}, especificando la 
	dirección	TSAP del servicio que desean, si no hay ningún servidor esperándolos, 
	consiguen una conexión al servidor de procesos.
	 \par Tras obtener la solicitud entrante el servidor de procesos genera el servidor 
	 solicitado, permitiéndole heredar la conexión con el usuario existente. El nuevo 
	 servidor entonces hace el trabajo requerido, mientras que el servidor de procesos 
	 retorna a escuchar solicitudes nuevas.
	\par Hay muchas situaciones en las que los servicios existen independientemente 
	del servidor de procesos. Por ejemplo, un servidor de archivos necesita operar en un 
	hardware especial (una máquina con un disco) y no puede crearse simplemente 
	sobre la marcha cuando alguien quiere comunicarse con él.
	
	\begin{center}
	\includegraphics[width=9cm, height=6cm]{./imagenes/conexioninicial.png} 
	\end{center}

	\item  \underline{Solución 3:} Existe un proceso especial llamado \textbf{servidor 
	de nombres} (también llamado servidor de directorio); para encontrar la dirección 
	TSAP correspondiente a un nombre de servicio dado, el usuario establece una 
	conexión con el servidor de nombres (que escucha en un TSAP bien conocido). 
	Entonces el 	usuario envía un mensaje especificando el nombre del servicio y el 
	servidor de nombres le devuelve la dirección TSAP, luego el usuario libera la 
	conexión con el servidor de nombres y establece una nueva con el servicio deseado. 
	Al crearse un servicio nuevo debe registrarse en el servidor de nombres, dando su 
	nombre de servicio como la dirección de su TSAP. El servidor de nombres registra 
	esta 	información en su base de datos.
\end{itemize} 

\subsection{Establecimiento de una conexión}
A primera vista parecería suficiente con que una entidad de transporte enviara tan 
sólo un segmento CONNECTION REQUEST al destino y esperara una respuesta CONNECTION ACCEPTED. El problema ocurre cuando la red puede perder, retrasar, corromper y duplicar paquetes. Este comportamiento causa complicaciones serias.
\par Imaginemos una subred de datagramas muy congestionada en la que las confirmaciones de recepción casi nunca regresan a tiempo, cada paquete expira y se retransmite algunas veces siguiendo rutas distintas. Algunos paquetes podrían atorarse en un congestionamiento de tráfico de la subred y tardar mucho tiempo en llegar.
\par La peor pesadilla posible es la siguiente. Un usuario establece una conexión con un banco, envía mensajes indicando al banco que transfiera dinero a la cuenta de una persona y a continuación libera la conexión. Por mala fortuna cada paquete de la transacción se duplica y se almacena en la subred. Tras liberar la conexión todos los paquetes salen de la subred y llegan a destino en orden, solicitando al banco que abra una conexión nueva, transfiera dinero (nuevamente) y libere la conexión.
\par El banco no tiene manera de saber que son duplicados; debe suponer que esta es una segunda transacción independiente, y transfiere nuevamente el dinero. Estudiaremos el problema de los duplicados retrasados estudiando algoritmos para establecer conexión de una manera confiable, de modo que situaciones como la anterior no puedan ocurrir.
\par El problema se puede atacar de varias maneras, ninguna de las cuales es muy satisfactoria. Una es usar direcciones de \textbf{transporte desechables}. En este enfoque, cada vez que se requiere una dirección de transporte, se genera una nueva. Cuando una conexión es liberada, se descarta la dirección y no se vuelve a utilizar. Esta estrategia dificulta la conexión con un proceso.
\par Otra posibilidad es dar a cada conexión un identificador único (es decir, un número de secuencia que se incremente con cada conexión establecida) elegido por la parte iniciadora y puesto en cada segmento, incluyendo el que solicita la conexión. Después de liberar cada conexión, cada entidad de transporte puede actualizar una tabla que liste conexiones obsoletas como pares (entidad de transporte de igual, identificador de conexión). Cada vez que entre una solicitud de conexión, se puede verificar con la tabla para saber si pertenece a una conexión previamente liberada.
\par Por desgracia, este esquema tiene una falla básica: requiere que cada entidad de transporte mantenga una cierta cantidad de información histórica durante un tiempo indefinido. Esta historia debe persistir tanto en la máquina de origen como en la de destino. De lo contrario, si una máquina falla y pierde su memoria, ya no sabrá qué identificadores de conexión ya han utilizado sus iguales.
\par Debemos idear un mecanismo para eliminar a los paquetes viejos que aún andan vagando por ahí. Con esta restricción, el problema se vuelve algo más manejable.
El tiempo de vida de un paquete puede restringirse a un máximo conocido mediante el uso de una (o más) de las siguientes técnicas:

	\begin{enumerate}
		\item \textbf{Un diseño de red restringido:} se usa para evitar que los paquetes hagan ciclos, combinado con una manera de limitar el retardo por congestionamiento a través de la trayectoria más larga posible (ahora conocida).
		\item \textbf{Colocar un contador de saltos en cada paquete:} se inicializa el contador de saltos con un valor apropiado y se lo decrementa cada vez que se reenvía el paquete. El protocolo de red descarta cualquier paquete cuyo contador de saltos llega a cero.
		\item \textbf{Marcar el tiempo en cada paquete:} cada paquete lleva la hora en la que fue creado y los enrutadores se ponen de acuerdo en descartar cualquier paquete que haya rebasado cierto tiempo predeterminado. Se requiere que los relojes de los enrutadores estén sincronizados lo que no es una tarea fácil, a menos que se logre la sincronización externamente a la red.
	\end{enumerate}

\par Pero no solo los paquetes viejos deben eliminarse sino también sus ACK, ya que un ack viejo puede ser el causante de duplicados retrasados.
\par Introduciremos \textit{T}, que es un múltiplo pequeño del tiempo de vida de paquete máximo verdadero. El múltiplo depende del protocolo y tiene el efecto de hacer más grande a \textit{T}. Si esperamos un tiempo \textit{T} tras el envío de un paquete, podemos estar seguros que todos los rastros suyos ya han desaparecido, y que ni el ni sus ack aparecerán repentinamente de la nada para complicar el asunto. Al limitar los tiempos de vida de los paquetes, es posible proponer una manera a prueba de errores de establecer conexiones seguras.

\subsubsection{Método de Tomlinson}
\par La base del método es que el origen etiquete los segmentos con números de secuencia que no se vayan a reutilizar durante \textit{T} segundos. El periodo \textit{T} y la tasa de paquetes por segundo determinan el tamaño de los números de secuencia. De esta manera, sólo un paquete con un número de secuencia específico puede estar pendiente en cualquier momento dado. Aún puede haber duplicados de este paquete, en cuyo caso el destino debe descartarlos.
\par Sabiendo el tiempo de vida del paquete, el número de secuencia esperado y los números de secuencia de segmentos a confirmar se puede saber si un segmento que llega es duplicado o no. Si el paquete no expiró y su número de secuencia es menor que el número de secuencia esperado, entonces ya se lo recibió y confirmó, en cambio si su número de secuencia es el número de secuencia de uno de los segmentos a confirmar, entonces es duplicado.
\par Para resolver el problema de una máquina que pierde toda la memoria acerca de su estado tras de una caída, Tomlinson propuso equipar cada host con un reloj. Los relojes de los distintos hosts no necesitan estar sincronizados. Se supone que cada reloj tiene la forma de un contador binario que se incrementa a sí mismo a intervalos uniformes. Además, la cantidad de bits del contador debe ser igual o mayor que la cantidad de bits en los números de secuencia. Por último, y lo más importante, se supone que el reloj continúa operando aunque el host falle.
\par Cuando se establece una conexión, los \textit{k} bits de menor orden del reloj se usan como número de secuencia inicial de \textit{k} bits. Cada conexión comienza a numerar sus segmentos con un número de secuencia inicial diferente. El espacio de secuencia también debe ser lo bastante grande para que, para cuando los números de secuencia se reinicien, los segmentos antiguos con el mismo número de secuencia hayan desaparecido hace mucho tiempo. En la figura 6-10(a) se muestra esta relación lineal entre tiempo y números secuenciales iniciales.

\begin{center} 
	\includegraphics[width=8cm, height=6cm]{./imagenes/tomlinson.png} 
\end{center}

\par Una vez que ambas entidades de transporte han acordado un número de secuencia inicial, puede usarse cualquier protocolo para el control de flujo de datos. La curva inicial de números de secuencia (indicada por la línea gruesa de la figura anterior) no es realmente lineal, sino una escalera, ya que el reloj avanza en pasos discretos. Por sencillez ignoramos este detalle.

\par Para mantener los números de secuencia fuera de la región prohibida, necesitamos tener cuidado con dos aspectos. Si un host envía muchos datos con demasiada rapidez en una conexión recién abierta, el número de secuencia actual contra la curva de tiempo puede subir en forma más pronunciada que el número de secuencia inicial contra la curva de tiempo, lo cual provoca que el número de secuencia entre a la región prohibida. Para evitar que esto ocurra, la tasa máxima de datos en cualquier conexión es de un segmento por cada pulso de reloj. La entidad de transporte debe esperar hasta que el reloj emita un pulso antes de abrir una nueva conexión después de un reinicio por falla, no sea que el mismo número se utilice dos veces.
Ambos puntos son argumentos a favor de un pulso de reloj corto (unos cuantos milisegundos). Esto es suponiendo que la relación tiempo a número de secuencia inicial es la función identidad. La idea es mantener los números de segmento generados por debajo de la línea gruesa correspondiente a esa relación.

\par Entrar a la región prohibida por la parte inferior al enviar con demasiada rapidez no es la única forma de meterse en problemas. De la figura 6-10(b) podemos ver que, a cualquier tasa de datos menor que la tasa de reloj, la curva de números de secuencia actuales utilizados vs el tiempo entrará en un momento dado a la región prohibida desde la izquierda, mientras los números de secuencia se reinician. Entre mayor sea la pendiente de los números de secuencia actuales, más se retardará este evento. Justo antes de enviar cada segmento, la entidad de transporte debe comprobar que no esté a punto de entrar en la región prohibida; de ser así debe retardar el segmento durante \textit{T} segundos o resincronizar los números de secuencia.

\par El método basado en reloj resuelve el problema de no poder diferenciar los segmentos duplicados con retardo de los segmentos nuevos. Sin embargo, hay un inconveniente práctico en cuanto a su uso para establecer conexiones. Como por lo general no recordamos los números de secuencia de una conexión a otra en el destino, aún no tenemos forma de saber si un segmento CONNECTION REQUEST que contiene un número de secuencia inicial es un duplicado de una conexión reciente.

\par Para resolver este problema específico, Tomlinson (1975) desarrolló el acuerdo de tres vías (\textit{threeway handshake}). Este protocolo de establecimiento implica que un igual verifique con el otro que la solicitud de conexión sea realmente actual. El procedimiento normal de establecimiento al iniciar el \textit{host 1} se muestra en la figura 6-11(a). El \textit{host 1} escoge un número de secuencia, \textit{x}, y envía al \textit{host 2} un segmento CONNECTION REQUEST que contiene ese número. El \textit{host 2} responde con un segmento ACK para confirmar la recepción de \textit{x} y anunciar su propio número de secuencia inicial, \textit{y}. Por último, el \textit{host 1} confirma la recepción del número de secuencia inicial seleccionado por el \textit{host 2} en el primer segmento de datos que envía.

\begin{center} 
	\includegraphics[width=8cm, height=6cm]{./imagenes/tomlinson2.png} 
\end{center}

\par En la figura 6-11(b), el primer segmento es un CONNECTION REQUEST duplicado con retardo de una conexión antigua. Este segmento llega al \textit{host 2} sin el conocimiento del \textit{host 1}. El \textit{host 2} reacciona a este segmento y envía al \textit{host 1} un segmento ACK, para solicitar en efecto la comprobación de que el \textit{host 1} haya tratado realmente de establecer una nueva conexión. Cuando el \textit{host 1} rechaza el intento del \textit{host 2} por establecer una conexión, el \textit{host 2} se da cuenta de que fue engañado por un duplicado con retardo y abandona la conexión. De esta manera, un duplicado con retardo no causa daño.
\par El peor caso ocurre cuando en la subred deambulan tanto un segmento CONNECTION REQUEST con retardo como un ACK. Este caso se muestra en la figura 6-11(c). Como en el ejemplo anterior, el \textit{host 2} recibe un CONNECTION REQUEST con retardo y lo contesta. En este momento es imprescindible tener en cuenta que el \textit{host 2} ha propuesto usar y como número de secuencia inicial para el tráfico del \textit{host 2} al \textit{host 1}, sabiendo bien que no existen todavía segmentos que contengan el número de secuencia y ni confirmaciones de recepción de y. Cuando llega el segundo segmento con retardo al \textit{host 2}, el hecho de que se confirmó la recepción de z en lugar de y indica al \textit{host 2}2 que éste también es un duplicado antiguo. Lo importante que debemos tener en cuenta aquí es que no hay una combinación de segmentos antiguos que puedan provocar la falla del protocolo y permitan establecer una conexión accidental cuando nadie la quiere.

\subsection{Liberación de una conexión}

\subsection{Control de errores y almacenamiento en búfer}
\subsection{Multiplexión}
\subsection{Recuperación de fallas}
\section{Control de congestión}
\subsection{Asignación de ancho de banda deseable }
\subsection{Regulación de la tasa de envío}
\subsection{Cuestiones inalámbricas}
\section{Los protocolos de transporte de internet: UDP}
\subsection{Introducción a UDP}
\subsection{Llamada a procedimiento remoto}
\subsection{Protocolos de transporte en tiempo real}


\section{Los protocolos de transporte de internet: TCP}

\subsection{Introducción a TCP}
\par La mayoría de las aplicaciones en internet necesitan una entrega en secuencia 
confiable, para ellos se diseñó \textbf{TCP (Transmission Control Protocol)} que sirve 
para proporcionar un flujo de bytes confiable de extremo a extremo a través de una 
interred no confiable. TCP tiene un diseño que se adapta de manera dinámica a las 
propiedades de la interred y que se sobrepone a muchos tipos de fallas.
\par Cada máquina que soporta TCP tiene una entidad de transporte TCP (ETCP), ya 
sea un procedimiento de biblioteca, un proceso de usuario, o parte del kernel. En todos 
los casos maneja flujos TCP e interactúa con la capa IP. Una ETCP acepta flujos de 
datos de usuario de procesos locales, los divide en fragmentos que no excedan los 64 
KB, y envía cada fragmento como un datagrama IP independiente. Cuando los 
datagramas que contienen datos TCP llegan a una máquina, se pasan a la ETCP, la cual 
reconstruye los flujos de bytes originales. Usaremos la palabra TCP para referirnos: a 
veces a la ETCP y a veces al protocolo TCP.
\par La capa IP no proporciona ninguna garantía de que los datagramas se entregarán 
de manera apropiada, por lo que corresponde a TCP terminar los temporizadores y 
retransmitir los datagramas conforme sea necesario.
\par Los datagramas que llegan podrán hacerlo en el orden incorrecto, esto sucede 
cuando se trabaja con redes de datagramas. Corresponde a TCP reensamblarlos en 
mensajes en la secuencia apropiada ya que usualmente la capa de aplicación del 
receptor necesita procesar los mensajes en el orden en que fueron enviados.

\subsection{El modelo del servicio TCP}
\par El servicio TCP se obtiene al hacer que tanto el servidor como el cliente creen 
puntos terminales llamados \textbf{\textit{sockets}}. Cada socket tiene una dirección 
que consiste en la dirección IP del host, y un número de 16 bits llamado \textbf{puerto}, el cual es local a ese host. Un puerto es el nombre TCP para un TSAP.
\par Para obtener el servicio TCP se debe establecer de manera explícita una conexión entre el socket en la máquina emisora y uno en la máquina receptora. Un socket puede usarse para múltiples conexiones al mismo tiempo, dos o más conexiones pueden terminar en el mismo socket. Las conexiones se identifican mediante los identificadores de sockets de los dos extremos, es decir (socket1, socket2).
\par Todas las conexiones TCP son de dúplex total y de punto a punto.
	\begin{itemize}
		\item Dúplex total: el tráfico puede ir en ambas direcciones al mismo tiempo.
		\item Punto a punto: cada conexión tiene exactamente dos puntos finales.
		\item  TCP no soporta la multidifusión ni la difusión.
	\end{itemize}
\par Una conexión TCP es un flujo de bytes, no un flujo de mensajes. Los límites de los 
mensajes no se preservan de extremo a extremo.

\textbf{Ejemplo:} el proceso emisor realiza 4 escrituras de 512 B en el flujo TCP, tal 
vez estos datos se entreguen al proceso receptor como 4 fragmentos de 512 B, o dos 
fragmentos de 1024 B, o uno de 2048 B o de alguna otra forma.

	\begin{center}
	\includegraphics[width=14cm, height=4cm]{./imagenes/tcp.png} 
	\end{center}

\par No hay manera que el receptor detecte las unidades en las que se escribieron los 
datos. El software TCP no tiene idea de lo que significan los bytes y no le interesa 
averiguarlo.

\par Cuando una aplicación pasa datos a TCP, este decide si los envía inmediatamente 
o si los almacena en el búfer a fin de recolectar una gran cantidad y luego enviarlos al 
mismo tiempo. Sin embargo la aplicación algunas veces necesita que los datos se 
envíen de inmediato.

\textbf{Ejemplo:} si un usuario inicia una sesión con una máquina remota. Una vez que 
se termina una línea de comandos y se introduce un retorno de carro es esencial que la 
línea se envíe a la máquina remota inmediatamente y que no se almacene en el búfer 
hasta que llegue la siguiente línea. Para obtener los datos, las aplicaciones pueden 
utilizar el indicador \textbf{PUSH} que es una señal para TCP de que no debe retrasar 
la transmisión, si llegan indicadores PUSH antes de que el primero se haya transmitido 
(por ejemplo, debido a que la línea de salida está ocupada), TCP es libre de recolectar 
todos los datos con indicadores PUSH en un solo datagrama IP, sin ninguna separación 
entre las diversas piezas.

Cuando un usuario interactivo oprime las teclas \emph{Ctrl+C} o \textit{Supr} para 
interrumpir una operación remota que ha iniciado, la aplicación emisora coloca 
información de control en el flujo de datos y se la da a TCP junto con el indicador 
\textbf{URGENT}. Este evento ocasiona que TCP interrumpa el encolamiento de datos 
y transmita inmediatamente todo lo que tenga para esa conexión. Cuando el destino 
recibe los datos urgentes, se interrumpe la aplicación receptora, a fin de que pueda 
detener lo que está haciendo y que lea el flujo de datos para leer los datos urgentes.
El final de los datos urgentes se marca para que la aplicación sepa dónde terminan.
El inicio de estos no se marca; la aplicación tiene que averiguarlo.

\subsection{Direccionamiento en TCP}
\par Los numeros de puerto menores que 1024 están reservados para los servicios 
estándar que, por lo general, sólo los usuarios privilegiados pueden iniciar. Éstos se 
llaman \textbf{puertos bien conocidos}.

	\begin{center}
	\includegraphics[width=9cm, height=6cm]{./imagenes/protocolo.png} 
	\end{center}

\par Podría ser posible que el demonio FTP se conecte por sí solo al puerto 21 en 
tiempo de arranque, que el demonio SSH se conecte por sí solo al puerto 22 en tiempo 
de arranque, y así en lo sucesivo. Sin embargo, hacer lo anterior podría llenar la 
memoria con demonios que están inactivos la mayor parte del tiempo. En su lugar, lo 
que se hace por lo general es que un solo demonio, llamado \emph{demonio de 
Internet (inetd)}, se conecte por sí solo a múltiples puertos y espere la primera 
conexión entrante. Cuando eso ocurre, \emph{inetd} bifurca un nuevo proceso y 
ejecuta el demonio apropiado en él, para dejar que ese demonio maneje la solicitud. De 
esta forma, los demonios distintos a \textit{inetd} sólo están activos cuando hay 
trabajo para ellos. \emph{Inetd} consulta un \textbf{archivo de configuración} para 
saber cuál puerto utilizar. El administrador del sistema puede 
configurar el sistema para tener demonios permanentes en los puertos más ocupados 
e \emph{inetd} en los demás.

\subsection{El protocolo TCP}
\par Cada byte de una conexión TCP tiene su propio número de secuencia de 32 bits. 
Los múmeros de secuencia separados de 32 bits se usan para confirmaciones de 
recepción y para el mecanismo de ventana. La entidad TCP emisora y la receptora 
intercambian datos en forma de segmentos. Un segmento consiste en un encabezado 
TCP fijo de 20 bytes (más una parte opcional) seguido de 0 o más bytes de datos. El 
software de TCP decide el tamaño de los segmentos; puede acumular datos de varias 
escrituras para formar un segmento, o dividir los datos de una escritura en varios 
segmentos.
\par Hay dos límites que restringen el tamaño de segmento:
	\begin{itemize}
		\item Cada segmento incluido el encabezado TCP, debe caber en la carga útil de 
		65.515 bytes del IP.
		\item Cada red tiene una unidad máxima de transferencia (MTU) y cada segmento 
		debe caber en la MTU.
		\item En la práctica la MTU es generalmente de 1500 bytes (el tamaño de la 
		carga útil de Ethernet).
	\end{itemize}	 
\par Cuando un transmisor envía un segmento, también inicia un temporizador. Cuando 
llega el segmento a destino, la ETCP receptora devuelve un segmento (con datos si 
existen, de otro modo sin ellos) que contiene un número de confirmación de recepción 
igual al siguiente número de secuencia que espera recibir. Si el temporizador del emisor 
expira antes de la recepción de la confirmación, el emisor envía de nuevo el segmento.

\subsubsection{Problemas a manejar/resolver por TCP eficientemente:}
\begin{itemize}
	\item Pueden llegar segmentos fuera de orden, por lo que los bytes 3072-4095 
	podrían llegar pero no enviarse confirmación de recepción, porque los bytes 
	2048-3071 no han aparecido aún.
	\item También pueden retardarse segmentos en tránsito durante tanto tiempo que 
	el temporizador del emisor expira y los segmentos se retransmiten.
	\item Las retransmisiones podrían incluir rangos de bytes diferentes a los de la 
	transmisión original, lo cual requiere una administración cuidadosa para llevar el 
	control de los bytes que se han recibido correctamente en un momento 
	determinado. Esto es factible ya que cada byte del flujo tiene su propio
	desplazamiento único.
\end{itemize}

\subsection{El encabezado del segmento TCP}
\par En la figura 6-36 se muestra la distribución de un segmento TCP. Cada segmento 
comienza con un encabezado de formato fijo de 20 bytes. El encabezado fijo puede ir 
seguido de encabezado de opciones. Después de las opciones, si las hay, pueden 
continuar hasta 65535$-$20$-$20$=$65495 bytes de datos, donde los primeros 20 se 
refieren al encabezado IP y los segundos al encabezado TCP. Los segmentos sin datos 
son legales y se usan por lo común para confirmaciones de recepción y mensajes de 
control.

	\begin{center}
	\includegraphics[width=9cm, height=6cm]{./imagenes/encabezado.png} 
	\end{center}

\par Los campos de \textit{puerto de origen} y \textit{puerto de destino} identifican 
los puntos terminales locales de la conexión. La dirección de un puerto más la dirección 
IP del host forman un punto terminal único de 48 bits. Los puntos terminales de origen 
y de destino en conjunto identifican la conexión.
\par Los campos \textit{número de secuencia} y \textit{número de confirmación de 
recepción} desempeñan sus funciones normales. El segundo indica el siguiente byte 
esperado, no el último byte correctamente recibido. Ambos tienen 32 bits de longitud porque cada byte de datos está numerado en el flujo TCP.
\par La \textit{longitud del encabezado TCP} indica la cantidad de palabras de 32 
bits contenidas en el encabezado TCP. Esta información es necesaria porque el campo 
\textit{Opciones} es de longitud variable, por lo que el encabezado también. Este 
campo indica el comienzo de los datos en el segmento, medido en palabras de 32 bits, 
pero ese número es simplemente la longitud del encabezado en palabras. A 
continuación viene un campo de 6 bits que no se usa.
\par Luego vienen 8 indicadores de 1 bit:
	\begin{itemize}
		\item \textbf{CWR} y \textit{ECE} se utilizan para indicar congestión cuando se 
		usa ECN (Notificación Explícita de Congestión). ECE se establece para indicar una 
		\textit{ECN-Echo} a un emisor TCP y decirle que reduzca su velocidad cuando el 
		receptor TCP recibe una indicación de congestión de la red. CWR se establece 
		para indicar una \textit{Ventana de congestión} reducida del emisor TCP al 
		receptor TCP, de modo que sepa que el emisor redujo su velocidad y puede dejar 
		de enviar la \textit{Repetición de ECN}.
		\item \textbf{URG} se establece en 1 si está en uso el \textit{Apuntador Urgente}, el cual 
		sirve para indicar un desplazamiento en bytes a partir del número actual de 
		secuencia en el que se encuentran datos urgentes, sustituye los mensajes de 
		interrupción y un mecanismo rudimentario para permitir que el emisor envíe una 
		señal al receptor sin implicar al TCP en la razón de la interrupción.
		\item \textbf{ACK} se establece en 1 para indicar que el \textit{Número de confirmación 
		de recepción} es válido. Si es 0, el segmento no contiene una confirmación de 
		recepción, por lo que se ignora el campo de número de confirmación de 
		recepción.
		\item \textbf{PSH} indica datos que se deben transmitir de inmediato. Por este medio se 
		solicita atentamente al receptor que entregue los datos a la aplicación a su 
		llegada y no los almacene en búfer hasta la recepción de un búfer completo.
		\item \textbf{RST} se usa para restablecer de manera repentina una conexión 
		que se ha confundido debido a una falla de host o alguna otra razón. También se 
		usa para rechazar un segmento no válido o un intento de abrir una conexión. Por 
		lo general, si usted recibe un segmento con el bit RST encendido, tiene un 
		problema entre manos.
		\item \textbf{SYN} se usa para establecer conexiones, es decir, denotar 
		\textit{CONNECTION REQUEST} y \textit{CONNECTION ACCEPTED}.
		\item \textbf{FIN} se usa para liberar una conexión y especifica que el emisor no 
		tiene más datos que \textit{transmitir}. 
	\end{itemize}
\par El control de flujo en TCP se maneja mediante una ventana deslizante de tamaño 
variable. El campo \textit{Tamaño de ventana} indica la cantidad de bytes que se 
pueden enviar, comenzando por el byte cuya recepción se ha confirmado. Un campo 
de \textit{Tamaño de ventana} de 0 es válido e indica que se han recibido los bytes 
hasta \textit{Número de confrmación de recepción}$-$1.

\subsection{Establecimiento de una conexión TCP}

\par En TCP las conexiones se establecen mediante el acuerdo de tres vías. Para establecer una conexión, el \textbf{servidor} espera en forma pasiva una conexión entrante mediante la ejecución de las primitivas LISTEN y ACCEPT en ese orden, ya sea que se especifique un origen determinado o a nadie en particular.

\par Del otro lado el cliente ejecuta una primitiva CONNECT en la que especifica la dirección y el puerto con el que se desea conectar, el tamaño máximo de segmento TCP que está dispuesto a aceptar y de manera opcional algunos datos de usuario (por ejemplo, una contraseña). La primitiva CONNECT envía un segmento TCP con el bit SYN encendido y el bit ACK apagado, y espera una respuesta.

\par Cuando este segmento llega al destino, la entidad TCP de ahí revisa si hay un proceso que haya ejecutado una primitiva LISTEN en el puerto que se indica en el campo Puerto de destino. Si no lo hay, envía una respuesta con el bit RST encendido para rechazar la conexión.

\par Si algún proceso está escuchando en el puerto, ese proceso recibe el segmento TCP entrante y puede entonces aceptar o rechazar la conexión. Si la acepta, se devuelve un segmento de confirmación de recepción. La secuencia de segmentos TCP enviados en el caso normal se muestra en la figura 6-37(a). Observe que un segmento SYN consume 1 byte de espacio de secuencia, por lo que se puede reconocer sin ambigüedades.


\subsection{Liberación de una conexión TCP}
\subsection{Modelado de administración de conexiones TCP}
\subsection{Ventana deslizante de TCP}
\subsection{Administración de temporizadores de TCP}
\subsection{Control de congestión en TCP}
\subsection{El futuro de TCP}

\begin{thebibliography}{X}
\bibitem{Baz} \textsc{tanenbaun andrew S. y wetherall, david j.}
\textit{Redes de Computadoras}, Quinta edición,
\textsc{pearson educación}, México, 2012.
\bibitem{Dan} \textsc{durán, juan },
<<Redes y Sistemas Distribuidos, filminas de clase>>,
\textit{FaMAF, UNC}.
\end{thebibliography}

\end{document}
